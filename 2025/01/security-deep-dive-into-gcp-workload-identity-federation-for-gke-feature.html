<!DOCTYPE html>
<html lang="zh"  prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml" class="han-init">
<head>
    <title>Workload Identity Federation for GKE 特性探索 - mozillazg's Blog</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- share.css -->
    <link rel="stylesheet" href="/theme/cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css">


    <link href="https://mozillazg.com/favicon.ico" rel="icon">

<link rel="canonical" href="https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature.html">

        <meta name="author" content="mozillazg" />
        <meta name="keywords" content="security,kubernetes,k8s,gcp,gke,Workload Identity Federation for GKE,cloud-security" />
    <meta name="description" content="Workload Identity Federation for GKE 特性探索 - 本文将简单探索一下前段时间 GKE 官宣的名为 Workload Identity Federation for GKE 的特性。 功能介绍 Workload Identity Federation for GKE 是原有的 GKE Workload Identity 特性的改进版本, 核心的改进是减少了需要配置的信息，提升了用户体验。 使用方法 可以通过下面几个步骤体验该特性： 创建一个启用 Workload Identity Federation for GKE 特性的 GKE 集群。具体启用位置是：创建集群 - 安全 - 启用 Workload Identity。 为测试应用使用的 service account 关联 iam 角色，一个 service account 可以关联多个角色。比如: $ kubectl create ns demo-ns $ kubectl -n demo-ns create serviceaccount demo-sa $ gcloud projects add-iam-policy-binding projects/test-gke-XXX \ --role=roles/container.clusterViewer \ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \ --condition=None $ gcloud storage buckets add-iam-policy-binding gs://&lt;bucket-name&gt; \ --role=roles/storage.objectViewer \ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \ --condition=None 部署测试应用，测试应用的 pod 需要使用第 2 步对应的 namespace 和 service account 以及增加 nodeSelector 确保调度到启用了 Workload Identity Federation for GKE 特性的节点上: apiVersion: v1 kind: Pod metadata: name: test-pod namespace: demo-ns spec: nodeSelector: iam.gke.io/gke-metadata-server-enabled: &#34;true&#34; serviceAccountName: demo-sa containers: - name: test-pod image: google/cloud-sdk:slim command: [&#34;sleep&#34;,&#34;infinity&#34;] 待 pod running 后, 进入 test-pod 容器内，访问实例元数据服务获取 sts ..." />

    <style>
      .js-toc {
        margin-bottom: 20px;
      }
      .donate-modal {
        text-align: center;
      }
      #donate-modal-container .donate-image {
        max-height: 300px !important;
        min-height: inherit !important;
      }
    </style>

        <meta property="og:site_name" content="mozillazg's Blog" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Workload Identity Federation for GKE 特性探索"/>
        <meta property="og:url" content="https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature.html"/>
        <meta property="og:description" content="本文将简单探索一下前段时间 GKE 官宣的名为 Workload Identity Federation for GKE 的特性。 功能介绍 Workload Identity Federation for GKE 是原有的 GKE Workload Identity 特性的改进版本, 核心的改进是减少了需要配置的信息，提升了用户体验。 使用方法 可以通过下面几个步骤体验该特性： 创建一个启用 Workload Identity Federation for GKE 特性的 GKE 集群。具体启用位置是：创建集群 - 安全 - 启用 Workload Identity。 为测试应用使用的 service account 关联 iam 角色，一个 service account 可以关联多个角色。比如: $ kubectl create ns demo-ns $ kubectl -n demo-ns create serviceaccount demo-sa $ gcloud projects add-iam-policy-binding projects/test-gke-XXX \ --role=roles/container.clusterViewer \ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \ --condition=None $ gcloud storage buckets add-iam-policy-binding gs://&lt;bucket-name&gt; \ --role=roles/storage.objectViewer \ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \ --condition=None 部署测试应用，测试应用的 pod 需要使用第 2 步对应的 namespace 和 service account 以及增加 nodeSelector 确保调度到启用了 Workload Identity Federation for GKE 特性的节点上: apiVersion: v1 kind: Pod metadata: name: test-pod namespace: demo-ns spec: nodeSelector: iam.gke.io/gke-metadata-server-enabled: &#34;true&#34; serviceAccountName: demo-sa containers: - name: test-pod image: google/cloud-sdk:slim command: [&#34;sleep&#34;,&#34;infinity&#34;] 待 pod running 后, 进入 test-pod 容器内，访问实例元数据服务获取 sts token，实际的业务应用使用的官方 SDK 也将使用类似的方式访问实例元数据服务获取用于请求云产品 API 的 sts token。 $ gcloud auth print-access-token ya29.d.XXX $ curl -H &#34;Metadata-Flavor: Google&#34; http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token {&#34;access_token&#34;:&#34;ya29.d.XXX&#34;,&#34;expires_in&#34;:3423,&#34;token_type&#34;:&#34;Bearer&#34;} 获取的 sts token 将具有前面第 2 步所关联的所有角色的权限. $ gcloud container node-pools list --zone us-central1 --cluster test NAME MACHINE_TYPE DISK_SIZE_GB NODE_VERSION default-pool e2-medium 100 1.30.6-gke.1125000 $ curl -X GET -H &#34;Authorization: Bearer $(gcloud auth print-access-token)&#34; \ &#34;https://storage.googleapis.com/storage/v1/b/demo-gke-workload-identity-federation/o&#34; { &#34;kind&#34;: &#34;storage#objects&#34; } 工作流程 Workload Identity Federation for GKE 特性的工作流程如下： 当应用 Pod 容器内的程序请求实例元数据服务（访问 http://metadata.google.internal ，实际是访问 http://169.254.169.254:80 ） 获取 sts token 时, 该请求将被重定向到 169.254.169.252:988。 169.254.169.252:988 是节点上部署的 gke-metadata-server 服务所监听的端口。 gke-metadata-server 服务在收到请求后，将根据请求的 client ip 确定请求来自哪个 Pod， 然后再请求 apiserver 生成一个该 Pod 所使用的 service account 对应的 token。 gke-metadata-server 将使用获取的 service account token 访问 GCP 的 STS API 获取一个 sts token， 最后 gke-metadata-server 将获取到的 sts token 返回给客户端。 这个流程中有几个关键的组件和信息需要重点关注，下面将逐个说明。 gke-metadata-server 当在集群维度或节点池维度启用 Workload Identity Federation for GKE 特性时，集群内将自动部署一个名为 gke-metadata-server 的组件。 该组件的工作负载 YAML 如下: apiVersion: apps/v1 kind: DaemonSet metadata: annotations: deprecated.daemonset.template.generation: &#34;1&#34; labels: addonmanager.kubernetes.io/mode: Reconcile k8s-app: gke-metadata-server name: gke-metadata-server namespace: kube-system spec: minReadySeconds: 90 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: gke-metadata-server template: metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 monitoring.gke.io/path: /metricz creationTimestamp: null labels: addonmanager.kubernetes.io/mode: Reconcile k8s-app: gke-metadata-server spec: containers: - command: - /gke-metadata-server - --logtostderr - --token-exchange-endpoint=https://securetoken.googleapis.com/v1/identitybindingtoken - --workload-pool=test-gke-XXXXXX.svc.id.goog - --alts-service-suffixes-using-node-identity=storage.googleapis.com,bigtable.googleapis.com,bigtable2.googleapis.com,bigtablerls.googleapis.com,spanner.googleapis.com,spanner2.googleapis.com,spanner-rls.googleapis.com,grpclb.directpath.google.internal,grpclb-dualstack.directpath.google.internal,staging-wrenchworks.sandbox.googleapis.com,preprod-spanner.sandbox.googleapis.com,wrenchworks-loadtest.googleapis.com,wrenchworks-nonprod.googleapis.com - --identity-provider=https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test - --passthrough-ksa-list=anthos-identity-service:gke-oidc-envoy-sa,anthos-identity-service:gke-oidc-service-sa,gke-managed-dpv2-observability:hubble-relay,kube-system:antrea-controller,kube-system:container-watcher-pod-reader,kube-system:coredns,kube-system:egress-nat-controller,kube-system:event-exporter-sa,kube-system:fluentd-gcp-scaler,kube-system:gke-metrics-agent,kube-system:gke-spiffe-node-agent,kube-system:heapster,kube-system:konnectivity-agent,kube-system:kube-dns,kube-system:maintenance-handler,kube-system:metadata-agent,kube-system:network-metering-agent,kube-system:node-local-dns,kube-system:pkgextract-service,kube-system:pkgextract-cleanup-service,kube-system:securityprofile-controller,istio-system:istio-ingressgateway-service-account,istio-system:cluster-local-gateway-service-account,csm:csm-sync-agent,knative-serving:controller,kube-system:pdcsi-node-sa,kube-system:gcsfusecsi-node-sa,gmp-system:collector,gke-gmp-system:collector,gke-managed-cim:kube-state-metrics - --attributes=cluster-name=test,cluster-uid=392f63049deXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX,cluster-location=us-central1 - --cluster-uid=392f63049ded410XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX - --sts-endpoint=https://sts.googleapis.com - --token-exchange-mode=sts - --cloud-monitoring-endpoint=monitoring.googleapis.com:443 - --iam-cred-service-endpoint=https://iamcredentials.googleapis.com - --cluster-project-number=2318XXXXXXXX - --cluster-location=us-central1 - --cluster-name=test - --component-version=0.4.301 - --ksa-cache-mode=watchchecker - --kcp-allow-watch-checker=true - --enable-mds-csi-driver=true - --csi-socket=/csi/csi.sock - --volumes-db=/var/run/gkemds.gke.io/csi/volumes.boltdb env: - name: GOMEMLIMIT value: &#34;94371840&#34; image: us-central1-artifactregistry.gcr.io/gke-release/gke-release/gke-metadata-server:gke_metadata_server_20240702.00_p0@sha256:aea9cc887c91b9a05e5bb4bb604180772594a01f0828bbfacf30c77562ac7205 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: host: 127.0.0.1 path: /healthz port: 989 scheme: HTTP initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 3 name: gke-metadata-server ports: - containerPort: 987 name: alts protocol: TCP - containerPort: 988 name: metadata-server protocol: TCP - containerPort: 989 name: debug-port protocol: TCP readinessProbe: failureThreshold: 3 httpGet: host: 127.0.0.1 path: /healthz port: 989 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: memory: 100Mi requests: cpu: 100m memory: 100Mi securityContext: privileged: true readOnlyRootFilesystem: true terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/lib/kubelet/kubeconfig name: kubelet-credentials readOnly: true - mountPath: /var/lib/kubelet/pki/ name: kubelet-certs readOnly: true - mountPath: /var/run/ name: container-runtime-interface - mountPath: /etc/srv/kubernetes/pki name: kubelet-pki readOnly: true - mountPath: /etc/ssl/certs/ name: ca-certificates readOnly: true - mountPath: /home/kubernetes/bin/gke-exec-auth-plugin name: gke-exec-auth-plugin readOnly: true - mountPath: /sys/firmware/efi/efivars/ name: efivars readOnly: true - mountPath: /dev/tpm0 name: vtpm readOnly: true - mountPath: /csi name: csi-socket-dir - mountPath: /var/run/gkemds.gke.io/csi name: state-dir - mountPath: /var/lib/kubelet/pods mountPropagation: Bidirectional name: pods-dir - mountPath: /registration name: kubelet-registration-dir dnsPolicy: Default hostNetwork: true nodeSelector: iam.gke.io/gke-metadata-server-enabled: &#34;true&#34; kubernetes.io/os: linux priorityClassName: system-node-critical restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: gke-metadata-server serviceAccountName: gke-metadata-server terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute operator: Exists - effect: NoSchedule operator: Exists - key: components.gke.io/gke-managed-components operator: Exists volumes: - hostPath: path: /var/lib/kubelet/pki/ type: Directory name: kubelet-certs - hostPath: path: /var/lib/kubelet/kubeconfig type: File name: kubelet-credentials - hostPath: path: /var/run/ type: Directory name: container-runtime-interface - hostPath: path: /etc/srv/kubernetes/pki/ type: Directory name: kubelet-pki - hostPath: path: /etc/ssl/certs/ type: Directory name: ca-certificates - hostPath: path: /home/kubernetes/bin/gke-exec-auth-plugin type: File name: gke-exec-auth-plugin - hostPath: path: /sys/firmware/efi/efivars/ type: Directory name: efivars - hostPath: path: /dev/tpm0 type: CharDevice name: vtpm - hostPath: path: /var/lib/kubelet/plugins/gkemds.gke.io type: DirectoryOrCreate name: csi-socket-dir - hostPath: path: /var/lib/kubelet/pods type: Directory name: pods-dir - hostPath: path: /var/lib/kubelet/plugins_registry type: Directory name: kubelet-registration-dir - hostPath: path: /var/lib/kubelet/plugins type: Directory name: kubelet-plugins-dir - hostPath: path: /var/run/gkemds.gke.io/csi type: DirectoryOrCreate name: state-dir gke-metadata-server 组件具有如下特点： 组件的工作负载是一个 DaemonSet。 组件 Pod 使用 hostNetwork: true 以及 privileged: true 。 组件内的服务将监听 987, 988 以及 989 端口, 其中 988 端口将用于接收重定向过来的访问实例元数据服务的请求: $ ss -atnlp |grep gke LISTEN 0 1024 *:987 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=10)) LISTEN 0 1024 *:989 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=12)) LISTEN 0 1024 *:988 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=15)) 前面所说的 169.254.169.252 这个 IP 是本机 lo 的 IP 地址，所以 gke-metadata-server 监听的 988 端口 就包含了前面所说的 169.254.169.252:988 端口: 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet 169.254.169.252/32 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 所有启用了 Workload Identity Federation for GKE 特性的节点在初始化的时候都会配置如下 nftables 规则， 确保从业务容器内发起的请求元数据服务 (http://metadata.google.internal , 169.254.169.254:80) 的流量都会被重定向到组件所监听的 169.254.169.252:988 端口: table ip nat { chain PREROUTING { type nat hook prerouting priority dstnat; policy accept; counter packets 2143 bytes 169432 jump KUBE-SERVICES iifname != &#34;eth0&#34; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 8080 counter packets 0 bytes 0 dnat to 169.254.169.252:987 iifname != &#34;eth0&#34; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 80 counter packets 181 bytes 10860 dnat to 169.254.169.252:988 } } 前面说到组件将通过 client ip 确定请求的来源 pod 以及会请求 apiserver 获取 service account，这里就涉及到组件是使用的什么凭证来访问 apiserver。 组件使用的是节点上 kubelet 的凭证来访问的 apiserver（前面的组件 YAML 中包含了挂载 kubelet kubeconfig 的配置）。 同时在部署组件时，将额外为 kubelet 的凭证授予 pods 和 serviceaccounts 的 get/list/watch RBAC 权限， 用于获取当前节点的 pod 以及 service account 信息: --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 labels: addonmanager.kubernetes.io/mode: Reconcile name: gce:gke-metadata-server-reader roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: gce:gke-metadata-server-reader subjects: - apiGroup: rbac.authorization.k8s.io kind: Group name: system:nodes --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 labels: addonmanager.kubernetes.io/mode: Reconcile name: gce:gke-metadata-server-reader rules: - apiGroups: - &#34;&#34; resources: - pods - serviceaccounts verbs: - get - watch - list 如果 pod 使用的 service account 没有绑定 IAM 角色，pod 内应用访问元数据服务获取的 sts token 将会是节点默认的 google serivce account 的 sts token。 service account token 对于每个 pod 内程序发起的请求，gke-metadata-server 组件不是直接使用 pod 容器所挂载 service account token， 而是请求 apiserver 生成了一份新的 service account token。 容器所挂载的 service account token 的 payload 示例如下: { &#34;aud&#34;: [ &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34; ], &#34;exp&#34;: ..., &#34;iat&#34;: ..., &#34;iss&#34;: &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;jti&#34;: &#34;...&#34;, &#34;kubernetes.io&#34;: {...}, &#34;nbf&#34;: ..., &#34;sub&#34;: &#34;system:serviceaccount:demo-ns:demo-sa&#34; } 组件请求 apiserver 所生成的 service account token 的 payload 示例如下: { &#34;aud&#34;: [ &#34;test-gke-XXXXXX.svc.id.goog&#34; ], &#34;exp&#34;: ..., &#34;iat&#34;: ..., &#34;iss&#34;: &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;jti&#34;: &#34;...&#34;, &#34;kubernetes.io&#34;: {...}, &#34;nbf&#34;: ..., &#34;sub&#34;: &#34;system:serviceaccount:demo-ns:demo-sa&#34; } 可以看到，主要的区别是 aud 的内容不一样。 sts token gke-metadata-server 组件将使用获取到的 service account token 访问 STS 的 token API 获取一份 sts token。 对应的请求示例如下: :authority: sts.googleapis.com :method: POST :path: /v1/token?alt=json&amp;prettyPrint=false :scheme: https x-goog-api-client: gl-go/1.23.0--20240626-RC01 cl/646990413 +5a18e79687 X:fieldtrack,boringcrypto gdcl/0.177.0 user-agent: google-api-go-client/0.5 gke-metadata-server content-type: application/json content-length: 1673 accept-encoding: gzip {&#34;audience&#34;:&#34;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;,&#34;grantType&#34;:&#34;urn:ietf:params:oauth:grant-type:token-exchange&#34;,&#34;requestedTokenType&#34;:&#34;urn:ietf:params:oauth:token-type:access_token&#34;,&#34;scope&#34;:&#34;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&#34;,&#34;subjectToken&#34;:&#34;XXX.XXX.XXX&#34;,&#34;subjectTokenType&#34;:&#34;urn:ietf:params:oauth:token-type:jwt&#34;} :status: 200 content-type: application/json; charset=UTF-8 vary: Origin vary: X-Origin vary: Referer content-encoding: gzip date: ... server: scaffolding on HTTPServer2 content-length: 1061 x-xss-protection: 0 x-frame-options: SAMEORIGIN x-content-type-options: nosniff {&#34;access_token&#34;:&#34;ya29.d.XXX&#34;,&#34;issued_token_type&#34;:&#34;urn:ietf:params:oauth:token-type:access_token&#34;,&#34;token_type&#34;:&#34;Bearer&#34;,&#34;expires_in&#34;:3599} 其中请求 body 格式化后的内容如下: { &#34;audience&#34;: &#34;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;grantType&#34;: &#34;urn:ietf:params:oauth:grant-type:token-exchange&#34;, &#34;requestedTokenType&#34;: &#34;urn:ietf:params:oauth:token-type:access_token&#34;, &#34;scope&#34;: &#34;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&#34;, &#34;subjectToken&#34;: &#34;XXX.XXX.XXX&#34;, &#34;subjectTokenType&#34;: &#34;urn:ietf:params:oauth:token-type:jwt&#34; } 响应 body 格式化后的内容如下: { &#34;access_token&#34;: &#34;ya29.d.XXX&#34;, &#34;issued_token_type&#34;: &#34;urn:ietf:params:oauth:token-type:access_token&#34;, &#34;token_type&#34;: &#34;Bearer&#34;, &#34;expires_in&#34;: 3599 } 与 GKE Workload Identity 的区别 Workload Identity Federation for GKE 与 GKE Workload Identity 特性（又叫 link Kubernetes ServiceAccounts to IAM）的区别如下： 比较项 GKE Workload Identity Workload Identity Federation for GKE 需要创建 Google service account (GSA) 需要 不需要 需要配置 GSA 绑定的 IAM 角色 需要 需要配置 k8s service account (KSA) 绑定的角色 需要配置允许使用 KSA 扮演 GSA 需要 不需要 需要在集群内配置 KSA 的 GSA 信息 需要 不需要 绑定角色时支持指定多个 KSA/GSA 不支持 支持 指定多个，比如某个命名空间下的所有SA, 某个集群内的所有SA 不支持使用 hostNetwork 的应用 不支持 不支持 依赖部署 gke-metadata-server 组件 依赖 依赖 云产品API对获取的 sts token 的支持情况 几乎所有云产品 API 都支持 大部分云产品API都支持，部分云产品有限支持，少量云产品不支持 BTW, 虽然 Workload Identity Federation for GKE 方案的官方教程和文档中都是说的需要依赖 gke-metadata-server 这个组件， 但是从前面的内容中我们也可以看到：我们其实也可以在不安装 gke-metadata-server 组件的情况下，使用该方案。 具体来说就是，我们可以通过为应用 Pod 挂载所需的 service account token 然后在应用程序内直接访问 STS 提供的 Token API 的方式来解除对该组件的依赖。 参考资料 Make IAM for GKE easier to use with Workload Identity Federation | Google Cloud Blog Authenticate to Google Cloud APIs from GKE workloads  |  Google Kubernetes Engine (GKE) About Workload Identity Federation for GKE  |  Google Kubernetes Engine (GKE)  |  Google Cloud Identity federation: products and limitations  |  IAM Documentation  |  Google Cloud Method: token  |  IAM Documentation  |  Google Cloud About VM metadata  |  Compute Engine Documentation  |  Google Cloud"/>
        <meta property="article:published_time" content="2025-01-05" />
            <meta property="article:section" content="security" />
            <meta property="article:tag" content="security" />
            <meta property="article:tag" content="kubernetes" />
            <meta property="article:tag" content="k8s" />
            <meta property="article:tag" content="gcp" />
            <meta property="article:tag" content="gke" />
            <meta property="article:tag" content="Workload Identity Federation for GKE" />
            <meta property="article:tag" content="cloud-security" />
            <meta property="article:author" content="mozillazg" />
            <meta property="og:image"
                  content="https://mozillazg.com/static/avatar.jpeg"/>


    <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@mozillazg">
        <meta name="twitter:creator" content="@mozillazg">
    <meta name="twitter:domain" content="https://mozillazg.com">
            <meta property="twitter:image"
                  content="https://mozillazg.com/static/avatar.jpeg"/>

    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/cdn.jsdelivr.net/npm/bootstrap@3.3.4/dist/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/cdn.jsdelivr.net/npm/font-awesome@4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/cdn.jsdelivr.net/npm/pygments-css@1.0.0/github.css" rel="stylesheet">
    <link rel="stylesheet" href="https://mozillazg.com/theme/css/style.css" type="text/css"/>
            <link href="/static/han.min.css" rel="stylesheet">
            <link href="/static/yue.css" rel="stylesheet">
            <link href="/static/custom.css" rel="stylesheet">

        <link href="https://mozillazg.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="mozillazg's Blog ATOM Feed"/>

        <link href="https://mozillazg.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="mozillazg's Blog RSS Feed"/>


        <link href="https://mozillazg.com/feeds/security.atom.xml" type="application/atom+xml" rel="alternate"
              title="mozillazg's Blog security ATOM Feed"/>


    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "publisher": {
            "@type": "Person",
            "name": "mozillazg",
            "logo": "https://mozillazg.com/static/avatar.jpeg"
        },
        "author": {
            "@type": "Person",
            "name": "mozillazg",
            "image": "https://mozillazg.com/static/avatar.jpeg",
            "url": "https://mozillazg.com",
            "sameAs": []
        },
        "headline": "Workload Identity Federation for GKE 特性探索",
        "url": "https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature.html",
        "image": [
            "https://mozillazg.com/static/avatar.jpeg"
         ],
        "keywords": "security, kubernetes, k8s, gcp, gke, Workload Identity Federation for GKE, cloud-security",
        "description": "本文将简单探索一下前段时间 GKE 官宣的名为 Workload Identity Federation for GKE 的特性。 功能介绍 Workload Identity Federation for GKE 是原有的 GKE Workload Identity 特性的改进版本, 核心的改进是减少了需要配置的信息，提升了用户体验。 使用方法 可以通过下面几个步骤体验该特性： 创建一个启用 Workload Identity Federation for GKE 特性的 GKE 集群。具体启用位置是：创建集群 - 安全 - 启用 Workload Identity。 为测试应用使用的 service account 关联 iam 角色，一个 service account 可以关联多个角色。比如: $ kubectl create ns demo-ns $ kubectl -n demo-ns create serviceaccount demo-sa $ gcloud projects add-iam-policy-binding projects/test-gke-XXX \\ --role=roles/container.clusterViewer \\ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \\ --condition=None $ gcloud storage buckets add-iam-policy-binding gs://&lt;bucket-name&gt; \\ --role=roles/storage.objectViewer \\ --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \\ --condition=None 部署测试应用，测试应用的 pod 需要使用第 2 步对应的 namespace 和 service account 以及增加 nodeSelector 确保调度到启用了 Workload Identity Federation for GKE 特性的节点上: apiVersion: v1 kind: Pod metadata: name: test-pod namespace: demo-ns spec: nodeSelector: iam.gke.io/gke-metadata-server-enabled: &#34;true&#34; serviceAccountName: demo-sa containers: - name: test-pod image: google/cloud-sdk:slim command: [&#34;sleep&#34;,&#34;infinity&#34;] 待 pod running 后, 进入 test-pod 容器内，访问实例元数据服务获取 sts token，实际的业务应用使用的官方 SDK 也将使用类似的方式访问实例元数据服务获取用于请求云产品 API 的 sts token。 $ gcloud auth print-access-token ya29.d.XXX $ curl -H &#34;Metadata-Flavor: Google&#34; http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token {&#34;access_token&#34;:&#34;ya29.d.XXX&#34;,&#34;expires_in&#34;:3423,&#34;token_type&#34;:&#34;Bearer&#34;} 获取的 sts token 将具有前面第 2 步所关联的所有角色的权限. $ gcloud container node-pools list --zone us-central1 --cluster test NAME MACHINE_TYPE DISK_SIZE_GB NODE_VERSION default-pool e2-medium 100 1.30.6-gke.1125000 $ curl -X GET -H &#34;Authorization: Bearer $(gcloud auth print-access-token)&#34; \\ &#34;https://storage.googleapis.com/storage/v1/b/demo-gke-workload-identity-federation/o&#34; { &#34;kind&#34;: &#34;storage#objects&#34; } 工作流程 Workload Identity Federation for GKE 特性的工作流程如下： 当应用 Pod 容器内的程序请求实例元数据服务（访问 http://metadata.google.internal ，实际是访问 http://169.254.169.254:80 ） 获取 sts token 时, 该请求将被重定向到 169.254.169.252:988。 169.254.169.252:988 是节点上部署的 gke-metadata-server 服务所监听的端口。 gke-metadata-server 服务在收到请求后，将根据请求的 client ip 确定请求来自哪个 Pod， 然后再请求 apiserver 生成一个该 Pod 所使用的 service account 对应的 token。 gke-metadata-server 将使用获取的 service account token 访问 GCP 的 STS API 获取一个 sts token， 最后 gke-metadata-server 将获取到的 sts token 返回给客户端。 这个流程中有几个关键的组件和信息需要重点关注，下面将逐个说明。 gke-metadata-server 当在集群维度或节点池维度启用 Workload Identity Federation for GKE 特性时，集群内将自动部署一个名为 gke-metadata-server 的组件。 该组件的工作负载 YAML 如下: apiVersion: apps/v1 kind: DaemonSet metadata: annotations: deprecated.daemonset.template.generation: &#34;1&#34; labels: addonmanager.kubernetes.io/mode: Reconcile k8s-app: gke-metadata-server name: gke-metadata-server namespace: kube-system spec: minReadySeconds: 90 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: gke-metadata-server template: metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 monitoring.gke.io/path: /metricz creationTimestamp: null labels: addonmanager.kubernetes.io/mode: Reconcile k8s-app: gke-metadata-server spec: containers: - command: - /gke-metadata-server - --logtostderr - --token-exchange-endpoint=https://securetoken.googleapis.com/v1/identitybindingtoken - --workload-pool=test-gke-XXXXXX.svc.id.goog - --alts-service-suffixes-using-node-identity=storage.googleapis.com,bigtable.googleapis.com,bigtable2.googleapis.com,bigtablerls.googleapis.com,spanner.googleapis.com,spanner2.googleapis.com,spanner-rls.googleapis.com,grpclb.directpath.google.internal,grpclb-dualstack.directpath.google.internal,staging-wrenchworks.sandbox.googleapis.com,preprod-spanner.sandbox.googleapis.com,wrenchworks-loadtest.googleapis.com,wrenchworks-nonprod.googleapis.com - --identity-provider=https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test - --passthrough-ksa-list=anthos-identity-service:gke-oidc-envoy-sa,anthos-identity-service:gke-oidc-service-sa,gke-managed-dpv2-observability:hubble-relay,kube-system:antrea-controller,kube-system:container-watcher-pod-reader,kube-system:coredns,kube-system:egress-nat-controller,kube-system:event-exporter-sa,kube-system:fluentd-gcp-scaler,kube-system:gke-metrics-agent,kube-system:gke-spiffe-node-agent,kube-system:heapster,kube-system:konnectivity-agent,kube-system:kube-dns,kube-system:maintenance-handler,kube-system:metadata-agent,kube-system:network-metering-agent,kube-system:node-local-dns,kube-system:pkgextract-service,kube-system:pkgextract-cleanup-service,kube-system:securityprofile-controller,istio-system:istio-ingressgateway-service-account,istio-system:cluster-local-gateway-service-account,csm:csm-sync-agent,knative-serving:controller,kube-system:pdcsi-node-sa,kube-system:gcsfusecsi-node-sa,gmp-system:collector,gke-gmp-system:collector,gke-managed-cim:kube-state-metrics - --attributes=cluster-name=test,cluster-uid=392f63049deXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX,cluster-location=us-central1 - --cluster-uid=392f63049ded410XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX - --sts-endpoint=https://sts.googleapis.com - --token-exchange-mode=sts - --cloud-monitoring-endpoint=monitoring.googleapis.com:443 - --iam-cred-service-endpoint=https://iamcredentials.googleapis.com - --cluster-project-number=2318XXXXXXXX - --cluster-location=us-central1 - --cluster-name=test - --component-version=0.4.301 - --ksa-cache-mode=watchchecker - --kcp-allow-watch-checker=true - --enable-mds-csi-driver=true - --csi-socket=/csi/csi.sock - --volumes-db=/var/run/gkemds.gke.io/csi/volumes.boltdb env: - name: GOMEMLIMIT value: &#34;94371840&#34; image: us-central1-artifactregistry.gcr.io/gke-release/gke-release/gke-metadata-server:gke_metadata_server_20240702.00_p0@sha256:aea9cc887c91b9a05e5bb4bb604180772594a01f0828bbfacf30c77562ac7205 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: host: 127.0.0.1 path: /healthz port: 989 scheme: HTTP initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 3 name: gke-metadata-server ports: - containerPort: 987 name: alts protocol: TCP - containerPort: 988 name: metadata-server protocol: TCP - containerPort: 989 name: debug-port protocol: TCP readinessProbe: failureThreshold: 3 httpGet: host: 127.0.0.1 path: /healthz port: 989 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: memory: 100Mi requests: cpu: 100m memory: 100Mi securityContext: privileged: true readOnlyRootFilesystem: true terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/lib/kubelet/kubeconfig name: kubelet-credentials readOnly: true - mountPath: /var/lib/kubelet/pki/ name: kubelet-certs readOnly: true - mountPath: /var/run/ name: container-runtime-interface - mountPath: /etc/srv/kubernetes/pki name: kubelet-pki readOnly: true - mountPath: /etc/ssl/certs/ name: ca-certificates readOnly: true - mountPath: /home/kubernetes/bin/gke-exec-auth-plugin name: gke-exec-auth-plugin readOnly: true - mountPath: /sys/firmware/efi/efivars/ name: efivars readOnly: true - mountPath: /dev/tpm0 name: vtpm readOnly: true - mountPath: /csi name: csi-socket-dir - mountPath: /var/run/gkemds.gke.io/csi name: state-dir - mountPath: /var/lib/kubelet/pods mountPropagation: Bidirectional name: pods-dir - mountPath: /registration name: kubelet-registration-dir dnsPolicy: Default hostNetwork: true nodeSelector: iam.gke.io/gke-metadata-server-enabled: &#34;true&#34; kubernetes.io/os: linux priorityClassName: system-node-critical restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: gke-metadata-server serviceAccountName: gke-metadata-server terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute operator: Exists - effect: NoSchedule operator: Exists - key: components.gke.io/gke-managed-components operator: Exists volumes: - hostPath: path: /var/lib/kubelet/pki/ type: Directory name: kubelet-certs - hostPath: path: /var/lib/kubelet/kubeconfig type: File name: kubelet-credentials - hostPath: path: /var/run/ type: Directory name: container-runtime-interface - hostPath: path: /etc/srv/kubernetes/pki/ type: Directory name: kubelet-pki - hostPath: path: /etc/ssl/certs/ type: Directory name: ca-certificates - hostPath: path: /home/kubernetes/bin/gke-exec-auth-plugin type: File name: gke-exec-auth-plugin - hostPath: path: /sys/firmware/efi/efivars/ type: Directory name: efivars - hostPath: path: /dev/tpm0 type: CharDevice name: vtpm - hostPath: path: /var/lib/kubelet/plugins/gkemds.gke.io type: DirectoryOrCreate name: csi-socket-dir - hostPath: path: /var/lib/kubelet/pods type: Directory name: pods-dir - hostPath: path: /var/lib/kubelet/plugins_registry type: Directory name: kubelet-registration-dir - hostPath: path: /var/lib/kubelet/plugins type: Directory name: kubelet-plugins-dir - hostPath: path: /var/run/gkemds.gke.io/csi type: DirectoryOrCreate name: state-dir gke-metadata-server 组件具有如下特点： 组件的工作负载是一个 DaemonSet。 组件 Pod 使用 hostNetwork: true 以及 privileged: true 。 组件内的服务将监听 987, 988 以及 989 端口, 其中 988 端口将用于接收重定向过来的访问实例元数据服务的请求: $ ss -atnlp |grep gke LISTEN 0 1024 *:987 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=10)) LISTEN 0 1024 *:989 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=12)) LISTEN 0 1024 *:988 *:* users:((&#34;gke-metadata-se&#34;,pid=183706,fd=15)) 前面所说的 169.254.169.252 这个 IP 是本机 lo 的 IP 地址，所以 gke-metadata-server 监听的 988 端口 就包含了前面所说的 169.254.169.252:988 端口: 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet 169.254.169.252/32 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 所有启用了 Workload Identity Federation for GKE 特性的节点在初始化的时候都会配置如下 nftables 规则， 确保从业务容器内发起的请求元数据服务 (http://metadata.google.internal , 169.254.169.254:80) 的流量都会被重定向到组件所监听的 169.254.169.252:988 端口: table ip nat { chain PREROUTING { type nat hook prerouting priority dstnat; policy accept; counter packets 2143 bytes 169432 jump KUBE-SERVICES iifname != &#34;eth0&#34; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 8080 counter packets 0 bytes 0 dnat to 169.254.169.252:987 iifname != &#34;eth0&#34; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 80 counter packets 181 bytes 10860 dnat to 169.254.169.252:988 } } 前面说到组件将通过 client ip 确定请求的来源 pod 以及会请求 apiserver 获取 service account，这里就涉及到组件是使用的什么凭证来访问 apiserver。 组件使用的是节点上 kubelet 的凭证来访问的 apiserver（前面的组件 YAML 中包含了挂载 kubelet kubeconfig 的配置）。 同时在部署组件时，将额外为 kubelet 的凭证授予 pods 和 serviceaccounts 的 get/list/watch RBAC 权限， 用于获取当前节点的 pod 以及 service account 信息: --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 labels: addonmanager.kubernetes.io/mode: Reconcile name: gce:gke-metadata-server-reader roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: gce:gke-metadata-server-reader subjects: - apiGroup: rbac.authorization.k8s.io kind: Group name: system:nodes --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: components.gke.io/component-name: gke-metadata-server components.gke.io/component-version: 0.4.301 labels: addonmanager.kubernetes.io/mode: Reconcile name: gce:gke-metadata-server-reader rules: - apiGroups: - &#34;&#34; resources: - pods - serviceaccounts verbs: - get - watch - list 如果 pod 使用的 service account 没有绑定 IAM 角色，pod 内应用访问元数据服务获取的 sts token 将会是节点默认的 google serivce account 的 sts token。 service account token 对于每个 pod 内程序发起的请求，gke-metadata-server 组件不是直接使用 pod 容器所挂载 service account token， 而是请求 apiserver 生成了一份新的 service account token。 容器所挂载的 service account token 的 payload 示例如下: { &#34;aud&#34;: [ &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34; ], &#34;exp&#34;: ..., &#34;iat&#34;: ..., &#34;iss&#34;: &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;jti&#34;: &#34;...&#34;, &#34;kubernetes.io&#34;: {...}, &#34;nbf&#34;: ..., &#34;sub&#34;: &#34;system:serviceaccount:demo-ns:demo-sa&#34; } 组件请求 apiserver 所生成的 service account token 的 payload 示例如下: { &#34;aud&#34;: [ &#34;test-gke-XXXXXX.svc.id.goog&#34; ], &#34;exp&#34;: ..., &#34;iat&#34;: ..., &#34;iss&#34;: &#34;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;jti&#34;: &#34;...&#34;, &#34;kubernetes.io&#34;: {...}, &#34;nbf&#34;: ..., &#34;sub&#34;: &#34;system:serviceaccount:demo-ns:demo-sa&#34; } 可以看到，主要的区别是 aud 的内容不一样。 sts token gke-metadata-server 组件将使用获取到的 service account token 访问 STS 的 token API 获取一份 sts token。 对应的请求示例如下: :authority: sts.googleapis.com :method: POST :path: /v1/token?alt=json&amp;prettyPrint=false :scheme: https x-goog-api-client: gl-go/1.23.0--20240626-RC01 cl/646990413 +5a18e79687 X:fieldtrack,boringcrypto gdcl/0.177.0 user-agent: google-api-go-client/0.5 gke-metadata-server content-type: application/json content-length: 1673 accept-encoding: gzip {&#34;audience&#34;:&#34;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;,&#34;grantType&#34;:&#34;urn:ietf:params:oauth:grant-type:token-exchange&#34;,&#34;requestedTokenType&#34;:&#34;urn:ietf:params:oauth:token-type:access_token&#34;,&#34;scope&#34;:&#34;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&#34;,&#34;subjectToken&#34;:&#34;XXX.XXX.XXX&#34;,&#34;subjectTokenType&#34;:&#34;urn:ietf:params:oauth:token-type:jwt&#34;} :status: 200 content-type: application/json; charset=UTF-8 vary: Origin vary: X-Origin vary: Referer content-encoding: gzip date: ... server: scaffolding on HTTPServer2 content-length: 1061 x-xss-protection: 0 x-frame-options: SAMEORIGIN x-content-type-options: nosniff {&#34;access_token&#34;:&#34;ya29.d.XXX&#34;,&#34;issued_token_type&#34;:&#34;urn:ietf:params:oauth:token-type:access_token&#34;,&#34;token_type&#34;:&#34;Bearer&#34;,&#34;expires_in&#34;:3599} 其中请求 body 格式化后的内容如下: { &#34;audience&#34;: &#34;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&#34;, &#34;grantType&#34;: &#34;urn:ietf:params:oauth:grant-type:token-exchange&#34;, &#34;requestedTokenType&#34;: &#34;urn:ietf:params:oauth:token-type:access_token&#34;, &#34;scope&#34;: &#34;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&#34;, &#34;subjectToken&#34;: &#34;XXX.XXX.XXX&#34;, &#34;subjectTokenType&#34;: &#34;urn:ietf:params:oauth:token-type:jwt&#34; } 响应 body 格式化后的内容如下: { &#34;access_token&#34;: &#34;ya29.d.XXX&#34;, &#34;issued_token_type&#34;: &#34;urn:ietf:params:oauth:token-type:access_token&#34;, &#34;token_type&#34;: &#34;Bearer&#34;, &#34;expires_in&#34;: 3599 } 与 GKE Workload Identity 的区别 Workload Identity Federation for GKE 与 GKE Workload Identity 特性（又叫 link Kubernetes ServiceAccounts to IAM）的区别如下： 比较项 GKE Workload Identity Workload Identity Federation for GKE 需要创建 Google service account (GSA) 需要 不需要 需要配置 GSA 绑定的 IAM 角色 需要 需要配置 k8s service account (KSA) 绑定的角色 需要配置允许使用 KSA 扮演 GSA 需要 不需要 需要在集群内配置 KSA 的 GSA 信息 需要 不需要 绑定角色时支持指定多个 KSA/GSA 不支持 支持 指定多个，比如某个命名空间下的所有SA, 某个集群内的所有SA 不支持使用 hostNetwork 的应用 不支持 不支持 依赖部署 gke-metadata-server 组件 依赖 依赖 云产品API对获取的 sts token 的支持情况 几乎所有云产品 API 都支持 大部分云产品API都支持，部分云产品有限支持，少量云产品不支持 BTW, 虽然 Workload Identity Federation for GKE 方案的官方教程和文档中都是说的需要依赖 gke-metadata-server 这个组件， 但是从前面的内容中我们也可以看到：我们其实也可以在不安装 gke-metadata-server 组件的情况下，使用该方案。 具体来说就是，我们可以通过为应用 Pod 挂载所需的 service account token 然后在应用程序内直接访问 STS 提供的 Token API 的方式来解除对该组件的依赖。 参考资料 Make IAM for GKE easier to use with Workload Identity Federation | Google Cloud Blog Authenticate to Google Cloud APIs from GKE workloads  |  Google Kubernetes Engine (GKE) About Workload Identity Federation for GKE  |  Google Kubernetes Engine (GKE)  |  Google Cloud Identity federation: products and limitations  |  IAM Documentation  |  Google Cloud Method: token  |  IAM Documentation  |  Google Cloud About VM metadata  |  Compute Engine Documentation  |  Google Cloud",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature.html"
        },
        "datePublished": "2025-01-05"
    }
    </script>

</head>
<body>

<div class="navbar" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://mozillazg.com/" class="navbar-brand">
mozillazg's Blog            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="https://mozillazg.com/feeds/all.atom.xml">Feed</a></li>
                    <li><a href="/2014/10/pages/about-me.html">About</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><a href="https://mozillazg.com/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-lg-12">
    <section id="content" class="yue">
        <article>
            <header class="text-center">
                <h1>
                    <a href="https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature.html"
                       rel="bookmark"
                       title="Permalink to Workload Identity Federation for GKE 特性探索">
                        Workload Identity Federation for GKE 特性探索
                    </a>
                </h1>
                <p class="published">
                    <time datetime="2025-01-05T00:00:00+00:00">
                    2025-01-05
                    </time>
                </p>
            </header>
            <div class="entry-content">
                <div class="well-sm article-info">
<footer class="post-info">
        <a href="https://mozillazg.com/category/security.html">security</a>


<span class="label label-default hide">Tags</span>
	<a href="https://mozillazg.com/tag/kubernetes.html">kubernetes</a>
        /
	<a href="https://mozillazg.com/tag/k8s.html">k8s</a>
        /
	<a href="https://mozillazg.com/tag/gcp.html">gcp</a>
        /
	<a href="https://mozillazg.com/tag/gke.html">gke</a>
        /
	<a href="https://mozillazg.com/tag/workload-identity-federation-for-gke.html">Workload Identity Federation for GKE</a>
        /
	<a href="https://mozillazg.com/tag/cloud-security.html">cloud-security</a>
    <span class="label label-default">Lang</span>
	<a href="https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature-en.html">en</a>

</footer><!-- /.post-info -->                </div>
                <div class="js-toc"></div>
                <div>
                <p>本文将简单探索一下前段时间 GKE 官宣的名为 <a class="reference external" href="https://cloud.google.com/blog/products/identity-security/make-iam-for-gke-easier-to-use-with-workload-identity-federation">Workload Identity Federation for GKE</a> 的特性。</p>
<div class="section" id="section-1">
<h2 id="hidsection-1">功能介绍<a class="headerlink" href="#hidsection-1" title="Permalink to this headline">¶</a></h2>
<p>Workload Identity Federation for GKE 是原有的 GKE Workload Identity 特性的改进版本,
核心的改进是减少了需要配置的信息，提升了用户体验。</p>
</div>
<div class="section" id="section-2">
<h2 id="hidsection-2">使用方法<a class="headerlink" href="#hidsection-2" title="Permalink to this headline">¶</a></h2>
<p>可以通过下面几个步骤体验该特性：</p>
<ol class="arabic">
<li><p class="first">创建一个启用 Workload Identity Federation for GKE 特性的 GKE 集群。具体启用位置是：创建集群 - 安全 - 启用 Workload Identity。</p>
</li>
<li><p class="first">为测试应用使用的 service account 关联 iam 角色，一个 service account 可以关联多个角色。比如:</p>
<pre class="literal-block">
$ kubectl create ns demo-ns
$ kubectl -n demo-ns create serviceaccount demo-sa

$ gcloud projects add-iam-policy-binding projects/test-gke-XXX \
    --role=roles/container.clusterViewer \
    --member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \
    --condition=None

$ gcloud storage buckets add-iam-policy-binding gs://&lt;bucket-name&gt; \
--role=roles/storage.objectViewer \
--member=principal://iam.googleapis.com/projects/23182XXXXXXX/locations/global/workloadIdentityPools/test-gke-XXXXXX.svc.id.goog/subject/ns/&lt;namespace-name&gt;/sa/&lt;service-account-name&gt; \
--condition=None
</pre>
</li>
<li><p class="first">部署测试应用，测试应用的 pod 需要使用第 2 步对应的 namespace 和 service account 以及增加 nodeSelector 确保调度到启用了 Workload Identity Federation for GKE 特性的节点上:</p>
<pre class="literal-block">
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
  namespace: demo-ns
spec:
  nodeSelector:
    iam.gke.io/gke-metadata-server-enabled: &quot;true&quot;
  serviceAccountName: demo-sa
  containers:
  - name: test-pod
    image: google/cloud-sdk:slim
    command: [&quot;sleep&quot;,&quot;infinity&quot;]
</pre>
</li>
<li><p class="first">待 pod running 后, 进入 test-pod 容器内，访问实例元数据服务获取 sts token，实际的业务应用使用的官方 SDK 也将使用类似的方式访问实例元数据服务获取用于请求云产品 API 的 sts token。</p>
</li>
</ol>
<div class="highlight"><pre><span></span>$<span class="w"> </span>gcloud<span class="w"> </span>auth<span class="w"> </span>print-access-token
<span class="w"> </span>ya29.d.XXX
$<span class="w"> </span>curl<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Metadata-Flavor: Google&quot;</span><span class="w"> </span>http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
<span class="w"> </span><span class="o">{</span><span class="s2">&quot;access_token&quot;</span>:<span class="s2">&quot;ya29.d.XXX&quot;</span>,<span class="s2">&quot;expires_in&quot;</span>:3423,<span class="s2">&quot;token_type&quot;</span>:<span class="s2">&quot;Bearer&quot;</span><span class="o">}</span>
</pre></div>
<ol class="arabic simple" start="5">
<li>获取的 sts token 将具有前面第 2 步所关联的所有角色的权限.</li>
</ol>
<div class="highlight"><pre><span></span>$<span class="w"> </span>gcloud<span class="w"> </span>container<span class="w"> </span>node-pools<span class="w"> </span>list<span class="w"> </span>--zone<span class="w"> </span>us-central1<span class="w"> </span>--cluster<span class="w"> </span><span class="nb">test</span>
<span class="w"> </span>NAME<span class="w">          </span>MACHINE_TYPE<span class="w">  </span>DISK_SIZE_GB<span class="w">  </span>NODE_VERSION
<span class="w"> </span>default-pool<span class="w">  </span>e2-medium<span class="w">     </span><span class="m">100</span><span class="w">           </span><span class="m">1</span>.30.6-gke.1125000

$<span class="w"> </span>curl<span class="w"> </span>-X<span class="w"> </span>GET<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Authorization: Bearer </span><span class="k">$(</span>gcloud<span class="w"> </span>auth<span class="w"> </span>print-access-token<span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span><span class="s2">&quot;https://storage.googleapis.com/storage/v1/b/demo-gke-workload-identity-federation/o&quot;</span>
<span class="w"> </span><span class="o">{</span>
<span class="w">   </span><span class="s2">&quot;kind&quot;</span>:<span class="w"> </span><span class="s2">&quot;storage#objects&quot;</span>
<span class="w"> </span><span class="o">}</span>
</pre></div>
</div>
<div class="section" id="section-3">
<h2 id="hidsection-3">工作流程<a class="headerlink" href="#hidsection-3" title="Permalink to this headline">¶</a></h2>
<p>Workload Identity Federation for GKE 特性的工作流程如下：</p>
<p><img alt="image" src="/static/images/security/gke-workload-identity-federation-for-gke.png" /></p>
<ol class="arabic simple">
<li>当应用 Pod 容器内的程序请求实例元数据服务（访问 <tt class="docutils literal"><span class="pre">http://metadata.google.internal</span></tt> ，实际是访问 <tt class="docutils literal"><span class="pre">http://169.254.169.254:80</span></tt> ）
获取 sts token 时, 该请求将被重定向到 169.254.169.252:988。
169.254.169.252:988 是节点上部署的 gke-metadata-server 服务所监听的端口。</li>
<li>gke-metadata-server 服务在收到请求后，将根据请求的 client ip 确定请求来自哪个 Pod，
然后再请求 apiserver 生成一个该 Pod 所使用的 service account 对应的 token。</li>
<li>gke-metadata-server 将使用获取的 service account token 访问 GCP 的
<a class="reference external" href="https://cloud.google.com/iam/docs/reference/sts/rest/v1/TopLevel/token">STS API</a> 获取一个 sts token，
最后 gke-metadata-server 将获取到的 sts token 返回给客户端。</li>
</ol>
<p>这个流程中有几个关键的组件和信息需要重点关注，下面将逐个说明。</p>
</div>
<div class="section" id="gke-metadata-server">
<h2 id="hidgke-metadata-server">gke-metadata-server<a class="headerlink" href="#hidgke-metadata-server" title="Permalink to this headline">¶</a></h2>
<p>当在集群维度或节点池维度启用 Workload Identity Federation for GKE 特性时，集群内将自动部署一个名为 gke-metadata-server 的组件。
该组件的工作负载 YAML 如下:</p>
<pre class="literal-block">
apiVersion: apps/v1
kind: DaemonSet
metadata:
  annotations:
    deprecated.daemonset.template.generation: &quot;1&quot;
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    k8s-app: gke-metadata-server
  name: gke-metadata-server
  namespace: kube-system
spec:
  minReadySeconds: 90
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: gke-metadata-server
  template:
    metadata:
      annotations:
        components.gke.io/component-name: gke-metadata-server
        components.gke.io/component-version: 0.4.301
        monitoring.gke.io/path: /metricz
      creationTimestamp: null
      labels:
        addonmanager.kubernetes.io/mode: Reconcile
        k8s-app: gke-metadata-server
    spec:
      containers:
      - command:
        - /gke-metadata-server
        - --logtostderr
        - --token-exchange-endpoint=https://securetoken.googleapis.com/v1/identitybindingtoken
        - --workload-pool=test-gke-XXXXXX.svc.id.goog
        - --alts-service-suffixes-using-node-identity=storage.googleapis.com,bigtable.googleapis.com,bigtable2.googleapis.com,bigtablerls.googleapis.com,spanner.googleapis.com,spanner2.googleapis.com,spanner-rls.googleapis.com,grpclb.directpath.google.internal,grpclb-dualstack.directpath.google.internal,staging-wrenchworks.sandbox.googleapis.com,preprod-spanner.sandbox.googleapis.com,wrenchworks-loadtest.googleapis.com,wrenchworks-nonprod.googleapis.com
        - --identity-provider=https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test
        - --passthrough-ksa-list=anthos-identity-service:gke-oidc-envoy-sa,anthos-identity-service:gke-oidc-service-sa,gke-managed-dpv2-observability:hubble-relay,kube-system:antrea-controller,kube-system:container-watcher-pod-reader,kube-system:coredns,kube-system:egress-nat-controller,kube-system:event-exporter-sa,kube-system:fluentd-gcp-scaler,kube-system:gke-metrics-agent,kube-system:gke-spiffe-node-agent,kube-system:heapster,kube-system:konnectivity-agent,kube-system:kube-dns,kube-system:maintenance-handler,kube-system:metadata-agent,kube-system:network-metering-agent,kube-system:node-local-dns,kube-system:pkgextract-service,kube-system:pkgextract-cleanup-service,kube-system:securityprofile-controller,istio-system:istio-ingressgateway-service-account,istio-system:cluster-local-gateway-service-account,csm:csm-sync-agent,knative-serving:controller,kube-system:pdcsi-node-sa,kube-system:gcsfusecsi-node-sa,gmp-system:collector,gke-gmp-system:collector,gke-managed-cim:kube-state-metrics
        - --attributes=cluster-name=test,cluster-uid=392f63049deXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX,cluster-location=us-central1
        - --cluster-uid=392f63049ded410XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
        - --sts-endpoint=https://sts.googleapis.com
        - --token-exchange-mode=sts
        - --cloud-monitoring-endpoint=monitoring.googleapis.com:443
        - --iam-cred-service-endpoint=https://iamcredentials.googleapis.com
        - --cluster-project-number=2318XXXXXXXX
        - --cluster-location=us-central1
        - --cluster-name=test
        - --component-version=0.4.301
        - --ksa-cache-mode=watchchecker
        - --kcp-allow-watch-checker=true
        - --enable-mds-csi-driver=true
        - --csi-socket=/csi/csi.sock
        - --volumes-db=/var/run/gkemds.gke.io/csi/volumes.boltdb
        env:
        - name: GOMEMLIMIT
          value: &quot;94371840&quot;
        image: us-central1-artifactregistry.gcr.io/gke-release/gke-release/gke-metadata-server:gke_metadata_server_20240702.00_p0&#64;sha256:aea9cc887c91b9a05e5bb4bb604180772594a01f0828bbfacf30c77562ac7205
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 989
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 3
        name: gke-metadata-server
        ports:
        - containerPort: 987
          name: alts
          protocol: TCP
        - containerPort: 988
          name: metadata-server
          protocol: TCP
        - containerPort: 989
          name: debug-port
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 989
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          privileged: true
          readOnlyRootFilesystem: true
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /var/lib/kubelet/kubeconfig
          name: kubelet-credentials
          readOnly: true
        - mountPath: /var/lib/kubelet/pki/
          name: kubelet-certs
          readOnly: true
        - mountPath: /var/run/
          name: container-runtime-interface
        - mountPath: /etc/srv/kubernetes/pki
          name: kubelet-pki
          readOnly: true
        - mountPath: /etc/ssl/certs/
          name: ca-certificates
          readOnly: true
        - mountPath: /home/kubernetes/bin/gke-exec-auth-plugin
          name: gke-exec-auth-plugin
          readOnly: true
        - mountPath: /sys/firmware/efi/efivars/
          name: efivars
          readOnly: true
        - mountPath: /dev/tpm0
          name: vtpm
          readOnly: true
        - mountPath: /csi
          name: csi-socket-dir
        - mountPath: /var/run/gkemds.gke.io/csi
          name: state-dir
        - mountPath: /var/lib/kubelet/pods
          mountPropagation: Bidirectional
          name: pods-dir
        - mountPath: /registration
          name: kubelet-registration-dir
      dnsPolicy: Default
      hostNetwork: true
      nodeSelector:
        iam.gke.io/gke-metadata-server-enabled: &quot;true&quot;
        kubernetes.io/os: linux
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: gke-metadata-server
      serviceAccountName: gke-metadata-server
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        operator: Exists
      - key: components.gke.io/gke-managed-components
        operator: Exists
      volumes:
      - hostPath:
          path: /var/lib/kubelet/pki/
          type: Directory
        name: kubelet-certs
      - hostPath:
          path: /var/lib/kubelet/kubeconfig
          type: File
        name: kubelet-credentials
      - hostPath:
          path: /var/run/
          type: Directory
        name: container-runtime-interface
      - hostPath:
          path: /etc/srv/kubernetes/pki/
          type: Directory
        name: kubelet-pki
      - hostPath:
          path: /etc/ssl/certs/
          type: Directory
        name: ca-certificates
      - hostPath:
          path: /home/kubernetes/bin/gke-exec-auth-plugin
          type: File
        name: gke-exec-auth-plugin
      - hostPath:
          path: /sys/firmware/efi/efivars/
          type: Directory
        name: efivars
      - hostPath:
          path: /dev/tpm0
          type: CharDevice
        name: vtpm
      - hostPath:
          path: /var/lib/kubelet/plugins/gkemds.gke.io
          type: DirectoryOrCreate
        name: csi-socket-dir
      - hostPath:
          path: /var/lib/kubelet/pods
          type: Directory
        name: pods-dir
      - hostPath:
          path: /var/lib/kubelet/plugins_registry
          type: Directory
        name: kubelet-registration-dir
      - hostPath:
          path: /var/lib/kubelet/plugins
          type: Directory
        name: kubelet-plugins-dir
      - hostPath:
          path: /var/run/gkemds.gke.io/csi
          type: DirectoryOrCreate
        name: state-dir
</pre>
<p>gke-metadata-server 组件具有如下特点：</p>
<ul>
<li><p class="first">组件的工作负载是一个 DaemonSet。</p>
</li>
<li><p class="first">组件 Pod 使用 <tt class="docutils literal">hostNetwork: true</tt> 以及 <tt class="docutils literal">privileged: true</tt> 。</p>
</li>
<li><p class="first">组件内的服务将监听 987, 988 以及 989 端口, 其中 988 端口将用于接收重定向过来的访问实例元数据服务的请求:</p>
<pre class="literal-block">
$ ss -atnlp |grep gke
LISTEN 0      1024               *:987              *:*    users:((&quot;gke-metadata-se&quot;,pid=183706,fd=10))
LISTEN 0      1024               *:989              *:*    users:((&quot;gke-metadata-se&quot;,pid=183706,fd=12))
LISTEN 0      1024               *:988              *:*    users:((&quot;gke-metadata-se&quot;,pid=183706,fd=15))
</pre>
</li>
<li><p class="first">前面所说的 169.254.169.252 这个 IP 是本机 lo 的 IP 地址，所以 gke-metadata-server 监听的 988 端口
就包含了前面所说的 <tt class="docutils literal">169.254.169.252:988</tt> 端口:</p>
<pre class="literal-block">
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet 169.254.169.252/32 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
</pre>
</li>
<li><p class="first">所有启用了 Workload Identity Federation for GKE 特性的节点在初始化的时候都会配置如下 nftables 规则，
确保从业务容器内发起的请求元数据服务 (<tt class="docutils literal"><span class="pre">http://metadata.google.internal</span></tt> , 169.254.169.254:80)
的流量都会被重定向到组件所监听的 <tt class="docutils literal">169.254.169.252:988</tt> 端口:</p>
<pre class="literal-block">
table ip nat {
        chain PREROUTING {
                type nat hook prerouting priority dstnat; policy accept;
                 counter packets 2143 bytes 169432 jump KUBE-SERVICES
                iifname != &quot;eth0&quot; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 8080  counter packets 0 bytes 0 dnat to 169.254.169.252:987
                iifname != &quot;eth0&quot; meta l4proto tcp ip daddr 169.254.169.254 tcp dport 80  counter packets 181 bytes 10860 dnat to 169.254.169.252:988
        }
}
</pre>
</li>
<li><p class="first">前面说到组件将通过 client ip 确定请求的来源 pod 以及会请求 apiserver 获取 service account，这里就涉及到组件是使用的什么凭证来访问 apiserver。
组件使用的是节点上 kubelet 的凭证来访问的 apiserver（前面的组件 YAML 中包含了挂载 kubelet kubeconfig 的配置）。
同时在部署组件时，将额外为 kubelet 的凭证授予 pods 和 serviceaccounts 的 get/list/watch RBAC 权限，
用于获取当前节点的 pod 以及 service account 信息:</p>
<pre class="literal-block">
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    components.gke.io/component-name: gke-metadata-server
    components.gke.io/component-version: 0.4.301
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
  name: gce:gke-metadata-server-reader
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: gce:gke-metadata-server-reader
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: system:nodes
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    components.gke.io/component-name: gke-metadata-server
    components.gke.io/component-version: 0.4.301
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
  name: gce:gke-metadata-server-reader
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  - serviceaccounts
  verbs:
  - get
  - watch
  - list
</pre>
</li>
<li><p class="first">如果 pod 使用的 service account 没有绑定 IAM 角色，pod 内应用访问元数据服务获取的 sts token 将会是节点默认的 google serivce account 的 sts token。</p>
</li>
</ul>
</div>
<div class="section" id="service-account-token">
<h2 id="hidservice-account-token">service account token<a class="headerlink" href="#hidservice-account-token" title="Permalink to this headline">¶</a></h2>
<p>对于每个 pod 内程序发起的请求，gke-metadata-server 组件不是直接使用 pod 容器所挂载 service account token，
而是请求 apiserver 生成了一份新的 service account token。</p>
<p>容器所挂载的 service account token 的 payload 示例如下:</p>
<pre class="literal-block">
{
  &quot;aud&quot;: [
    &quot;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&quot;
  ],
  &quot;exp&quot;: ...,
  &quot;iat&quot;: ...,
  &quot;iss&quot;: &quot;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&quot;,
  &quot;jti&quot;: &quot;...&quot;,
  &quot;kubernetes.io&quot;: {...},
  &quot;nbf&quot;: ...,
  &quot;sub&quot;: &quot;system:serviceaccount:demo-ns:demo-sa&quot;
}
</pre>
<p>组件请求 apiserver 所生成的 service account token 的 payload 示例如下:</p>
<pre class="literal-block">
{
  &quot;aud&quot;: [
    &quot;test-gke-XXXXXX.svc.id.goog&quot;
  ],
  &quot;exp&quot;: ...,
  &quot;iat&quot;: ...,
  &quot;iss&quot;: &quot;https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&quot;,
  &quot;jti&quot;: &quot;...&quot;,
  &quot;kubernetes.io&quot;: {...},
  &quot;nbf&quot;: ...,
  &quot;sub&quot;: &quot;system:serviceaccount:demo-ns:demo-sa&quot;
}
</pre>
<p>可以看到，主要的区别是 aud 的内容不一样。</p>
</div>
<div class="section" id="sts-token">
<h2 id="hidsts-token">sts token<a class="headerlink" href="#hidsts-token" title="Permalink to this headline">¶</a></h2>
<p>gke-metadata-server 组件将使用获取到的 service account token 访问 STS 的
<a class="reference external" href="https://cloud.google.com/iam/docs/reference/sts/rest/v1/TopLevel/token">token API</a> 获取一份 sts token。</p>
<p>对应的请求示例如下:</p>
<pre class="literal-block">
:authority: sts.googleapis.com
:method: POST
:path: /v1/token?alt=json&amp;prettyPrint=false
:scheme: https
x-goog-api-client: gl-go/1.23.0--20240626-RC01 cl/646990413 +5a18e79687 X:fieldtrack,boringcrypto gdcl/0.177.0
user-agent: google-api-go-client/0.5 gke-metadata-server
content-type: application/json
content-length: 1673
accept-encoding: gzip

{&quot;audience&quot;:&quot;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&quot;,&quot;grantType&quot;:&quot;urn:ietf:params:oauth:grant-type:token-exchange&quot;,&quot;requestedTokenType&quot;:&quot;urn:ietf:params:oauth:token-type:access_token&quot;,&quot;scope&quot;:&quot;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&quot;,&quot;subjectToken&quot;:&quot;XXX.XXX.XXX&quot;,&quot;subjectTokenType&quot;:&quot;urn:ietf:params:oauth:token-type:jwt&quot;}

:status: 200
content-type: application/json; charset=UTF-8
vary: Origin
vary: X-Origin
vary: Referer
content-encoding: gzip
date: ...
server: scaffolding on HTTPServer2
content-length: 1061
x-xss-protection: 0
x-frame-options: SAMEORIGIN
x-content-type-options: nosniff

{&quot;access_token&quot;:&quot;ya29.d.XXX&quot;,&quot;issued_token_type&quot;:&quot;urn:ietf:params:oauth:token-type:access_token&quot;,&quot;token_type&quot;:&quot;Bearer&quot;,&quot;expires_in&quot;:3599}
</pre>
<p>其中请求 body 格式化后的内容如下:</p>
<pre class="literal-block">
{
  &quot;audience&quot;: &quot;identitynamespace:test-gke-XXXXXX.svc.id.goog:https://container.googleapis.com/v1/projects/test-gke-XXXXXX/locations/us-central1/clusters/test&quot;,
  &quot;grantType&quot;: &quot;urn:ietf:params:oauth:grant-type:token-exchange&quot;,
  &quot;requestedTokenType&quot;: &quot;urn:ietf:params:oauth:token-type:access_token&quot;,
  &quot;scope&quot;: &quot;https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email&quot;,
  &quot;subjectToken&quot;: &quot;XXX.XXX.XXX&quot;,
  &quot;subjectTokenType&quot;: &quot;urn:ietf:params:oauth:token-type:jwt&quot;
}
</pre>
<p>响应 body 格式化后的内容如下:</p>
<pre class="literal-block">
{
  &quot;access_token&quot;: &quot;ya29.d.XXX&quot;,
  &quot;issued_token_type&quot;: &quot;urn:ietf:params:oauth:token-type:access_token&quot;,
  &quot;token_type&quot;: &quot;Bearer&quot;,
  &quot;expires_in&quot;: 3599
}
</pre>
</div>
<div class="section" id="gke-workload-identity">
<h2 id="hidgke-workload-identity">与 GKE Workload Identity 的区别<a class="headerlink" href="#hidgke-workload-identity" title="Permalink to this headline">¶</a></h2>
<p>Workload Identity Federation for GKE 与 GKE Workload Identity 特性（又叫 link Kubernetes ServiceAccounts to IAM）的区别如下：</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="26%" />
<col width="45%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">比较项</th>
<th class="head">GKE Workload Identity</th>
<th class="head">Workload Identity Federation for GKE</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>需要创建 Google service account (GSA)</td>
<td>需要</td>
<td><strong>不需要</strong></td>
</tr>
<tr><td>需要配置 GSA 绑定的 IAM 角色</td>
<td>需要</td>
<td>需要配置 k8s service account (KSA) 绑定的角色</td>
</tr>
<tr><td>需要配置允许使用 KSA 扮演 GSA</td>
<td>需要</td>
<td><strong>不需要</strong></td>
</tr>
<tr><td>需要在集群内配置 KSA 的 GSA 信息</td>
<td>需要</td>
<td><strong>不需要</strong></td>
</tr>
<tr><td>绑定角色时支持指定多个 KSA/GSA</td>
<td>不支持</td>
<td><strong>支持</strong> 指定多个，比如某个命名空间下的所有SA, 某个集群内的所有SA</td>
</tr>
<tr><td>不支持使用 hostNetwork 的应用</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr><td>依赖部署 gke-metadata-server 组件</td>
<td>依赖</td>
<td>依赖</td>
</tr>
<tr><td>云产品API对获取的 sts token 的支持情况</td>
<td>几乎所有云产品 API 都支持</td>
<td>大部分云产品API都支持，部分云产品有限支持，少量云产品不支持</td>
</tr>
</tbody>
</table>
<p>BTW, 虽然 Workload Identity Federation for GKE 方案的官方教程和文档中都是说的需要依赖 gke-metadata-server 这个组件，
但是从前面的内容中我们也可以看到：我们其实也可以在不安装 gke-metadata-server 组件的情况下，使用该方案。
具体来说就是，我们可以通过为应用 Pod 挂载所需的 service account token 然后在应用程序内直接访问
STS 提供的 Token API 的方式来解除对该组件的依赖。</p>
</div>
<div class="section" id="section-4">
<h2 id="hidsection-4">参考资料<a class="headerlink" href="#hidsection-4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://cloud.google.com/blog/products/identity-security/make-iam-for-gke-easier-to-use-with-workload-identity-federation">Make IAM for GKE easier to use with Workload Identity Federation | Google Cloud Blog</a></li>
<li><a class="reference external" href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Authenticate to Google Cloud APIs from GKE workloads &nbsp;|&nbsp; Google Kubernetes Engine (GKE)</a></li>
<li><a class="reference external" href="https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity">About Workload Identity Federation for GKE &nbsp;|&nbsp; Google Kubernetes Engine (GKE) &nbsp;|&nbsp; Google Cloud</a></li>
<li><a class="reference external" href="https://cloud.google.com/iam/docs/federated-identity-supported-services">Identity federation: products and limitations &nbsp;|&nbsp; IAM Documentation &nbsp;|&nbsp; Google Cloud</a></li>
<li><a class="reference external" href="https://cloud.google.com/iam/docs/reference/sts/rest/v1/TopLevel/token">Method: token &nbsp;|&nbsp; IAM Documentation &nbsp;|&nbsp; Google Cloud</a></li>
<li><a class="reference external" href="https://cloud.google.com/compute/docs/metadata/overview">About VM metadata &nbsp;|&nbsp; Compute Engine Documentation &nbsp;|&nbsp; Google Cloud</a></li>
</ul>
</div>

                </div>
            </div>
            <!-- /.entry-content -->
<section class="text-center">
  
<div id="donate"></div>

<div class="social-share"></div>
<div class="social-comment-note">
<p class="text-center">有任何建议和想法欢迎在下方评论区留言或者加我<a href="/static/wechat.png">微信</a>交流</p>
</div>

</section>
<section class="well" id="related-posts">
    <p>Related Posts:</p>
    <ul>
        <li><a href="https://mozillazg.com/2025/01/security-deep-dive-into-gcp-workload-identity-federation-for-gke-feature-en.html">Exploring Workload Identity Federation for GKE</a></li>
        <li><a href="https://mozillazg.com/2023/12/security-deep-dive-into-aws-eks-pod-identity-feature-en.html">Exploring the New Features of Amazon EKS Pod Identity</a></li>
        <li><a href="https://mozillazg.com/2023/12/security-deep-dive-into-aws-eks-pod-identity-feature.html">Amazon EKS Pod Identity 新特性探索</a></li>
        <li><a href="https://mozillazg.com/2020/07/k8s-kubernetes-client-go-list-get-create-update-patch-delete-crd-resource-without-generate-client-code-update-or-create-via-yaml.html">在不生成 crd client 代码的情况下通过 client-go 增删改查 k8s crd 资源</a></li>
        <li><a href="https://mozillazg.com/2020/06/k8s-kubernetes-kubectl-syntax-of-impersonate-as-user-or-serviceaccount-or-group.html">kubernetes 用户扮演 API</a></li>
    </ul>
</section>
<hr/>
<section class="comments" id="comments">
    <h2>Comments</h2>
    <script src="https://giscus.app/client.js"
            data-repo="mozillazg/mozillazg.github.com"
            data-repo-id="MDEwOlJlcG9zaXRvcnk3Njc4MTA2"
            data-category="Announcements"
            data-category-id="DIC_kwDOAHUoms4CckZl"
            data-mapping="pathname"
            data-strict="0"
            data-reactions-enabled="1"
            data-emit-metadata="0"
            data-input-position="bottom"
            data-theme="preferred_color_scheme"
            data-description="<description>"
            data-lang="en"
            data-loading="lazy"
            crossorigin="anonymous"
            async>
    </script>
</section>
        </article>
    </section>

        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2025 mozillazg
            &middot; Powered by <a href="https://github.com/DandyDev/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>
            &middot; <a href="/privacy-policy.html" target="_blank">Privacy</a>              <p><small>  <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/static/images/by-sa-80x15.png" /></a>
    &quot;<span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">mozillazg's Blog</span>&quot; by <a xmlns:cc="http://creativecommons.org/ns#" href="https://mozillazg.com" property="cc:attributionName" rel="cc:attributionURL">mozillazg</a> is
  licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/cdn.jsdelivr.net/npm/jquery@2.1.1/dist/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/cdn.jsdelivr.net/npm/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->


<!-- share.js -->
<script src="/theme/cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script>



<script src="/theme/cdn.jsdelivr.net/npm/tocbot@3.0.2/dist/tocbot.min.js"></script>
<script>
$(document).ready(function(){
  tocbot.init({
    // Where to render the table of contents.
    tocSelector: '.js-toc',
    // Where to grab the headings to build the table of contents.
    contentSelector: '.entry-content',
    // Which headings to grab inside of the contentSelector element.
    headingSelector: 'h2, h3, h4,h5',
    // Headings that match the ignoreSelector will be skipped.
    ignoreSelector: '.js-toc-ignore',
    // Main class to add to links.
    linkClass: 'toc-link',
    // Extra classes to add to links.
    extraLinkClasses: '',
    // Class to add to active links,
    // the link corresponding to the top most heading on the page.
    activeLinkClass: 'is-active-link',
    // Main class to add to lists.
    listClass: 'toc-list',
    // Extra classes to add to lists.
    extraListClasses: '',
    // Class that gets added when a list should be collapsed.
    isCollapsedClass: 'is-collapsed',
    // Class that gets added when a list should be able
    // to be collapsed but isn't necessarily collpased.
    collapsibleClass: 'is-collapsible',
    // Class to add to list items.
    listItemClass: 'toc-list-item',
    // How many heading levels should not be collpased.
    // For example, number 6 will show everything since
    // there are only 6 heading levels and number 0 will collpase them all.
    // The sections that are hidden will open
    // and close as you scroll to headings within them.
    collapseDepth: 6,
    // Smooth scrolling enabled.
    smoothScroll: true,
    // Smooth scroll duration.
    smoothScrollDuration: 420,
    // Callback for scroll end (requires: smoothScroll).
    scrollEndCallback: function (e) {},
    // Headings offset between the headings and the top of the document (this is meant for minor adjustments).
    headingsOffset: 0,
    // Timeout between events firing to make sure it's
    // not too rapid (for performance reasons).
    throttleTimeout: 50,
    // Element to add the positionFixedClass to.
    positionFixedSelector: null,
    // Fixed position class to add to make sidebar fixed after scrolling
    // down past the fixedSidebarOffset.
    positionFixedClass: 'is-position-fixed',
    // fixedSidebarOffset can be any number but by default is set
    // to auto which sets the fixedSidebarOffset to the sidebar
    // element's offsetTop from the top of the document on init.
    fixedSidebarOffset: 'auto',
    // includeHtml can be set to true to include the HTML markup from the
    // heading node instead of just including the textContent.
    includeHtml: false
  });
});
</script>
</body>
</html>